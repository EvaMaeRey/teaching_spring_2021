---
title: "Practice time"
output: 
  html_document:
    toc: true
    toc_depth: 2
---


# Setup

We'll use the tidyverse

```{r setup, include=F}
library(tidyverse)
```


# Part I. One proportion z test calculations

Below you will go through the steps in the course guide to do the theory based test - the one proportion z test.  

- Step 1 calculate sample proportion
- Step 2 calc sd for the null (chance) model
- Step 3 calc z stat
- Step 4 translate to p-value

> Example: Boxing in Red and Blue

You've done an exploration exercise with the data on Olympic events where opponents are randomly assigned to wear red or blue.  Researchers asked: Is there an advantage to being assigned one color over the other?

They observed that in 457 matches, 248 were won by the opponent wearing red.  

You used the applet for you exploration exercise. Now let's use R and Rmarkdown to go throught this.  Much is worked out for you, but you will be prompted to answer questions throughout.

## Part 1.a. Calculating the z-stat and p-value step-by-step

For an overview: check out the slides [here](ma206_lesson_06.html#73)

### Step 1: Calculate the statistic, p-hat.  

```{r theory_p_val_calc}
457 -> num_observations # number of matches

## calculate sample proportion p hat
248 / 457 -> # number of wins for red uniform wearer over total Olympic matches
  sample_proportion

sample_proportion
```


We'll use a little "MathJax" here too, which translates from plain text to equations which may contain fractions, special characters, sub- and superscripts. In the MathJax environment below, fenced by dollar signs, **replace the question mark with the calculated statistic, phat.**

$$ \hat{p} = ? $$

```{r}
# I can make a little data frame using tibble
tibble(color_of_winner = c("red", "blue"),
       count = c(248, 457-248)) ->
olympics_matches

olympics_matches


ggplot(data = olympics_matches) +
  aes(x = color_of_winner) +
  aes(y = count) +
  geom_col() +
  labs(title = "In 457 matches there are more winners that were\nrandomly assigned to wear red than\nwinners assigned blue") +
  labs(subtitle = "The observed split is not 50/50.\n But could it still have just arisen from chance?")
```



### Step 2: Use the null, $\pi$ to think about the distribution under the chance model  


```{r}
## establish pi
.5 -> 
  null_prob
```

**Replace the question mark with the value of $\pi$ for the null hypothesis and alternative hypothesis (this is two-sided).**

$$ H_0:  \pi = ? $$
$$ H_A:  \pi \neq ? $$
**Answer the following question:** Is $\pi$ a *population* parameter? In other words, are we trying to generalize to a population. Or does it describe an underlying rate for a process? 

> Your answer here...

Based on $\pi$ and the number of observations, how much variability is expected under the chance model?  We can use the formula to describe the variability - the standard deviation for the chance model:

$$ sd_{chance} =  \sqrt{\frac{\pi*(1-\pi)}{n}} $$
In R, as follows:

```{r}
## calc sd for the null:
sqrt((null_prob * (1-null_prob)) / num_observations ) ->
  sd_chance_model

sd_chance_model
```

Given that the distribution for the chance model is approximately normal, and what we know about 

![normal distributions](https://upload.wikimedia.org/wikipedia/commons/8/8c/Standard_deviation_diagram.svg) 

We expect ~68% of what's observed just under chance variation to fall within 1 standard deviation or the range .5 plus or minus...

$$ .5 \pm ? $$
We expect 95.5% of the variation under the chance model to happend within 2 standard deviations of $\pi$, or .5 plus or minus ...

$$ .5 \pm ? $$

Let's visualize the normal distribution that is implied by the standard deviation we've calculated.

```{r}
tibble(x = 400:600/1000) %>% 
  mutate(density = 
           dnorm(x, 
                 mean = .5, 
                 sd = sd_chance_model)) ->
normal_density_25percent_15observations

ggplot(data = normal_density_25percent_15observations) + 
  aes(x = x) +
  aes(y = density) + 
  geom_area(alpha = .75) + # null model
  geom_vline(xintercept = null_prob) # expectation under the null
```  
  
Execute the following code.  What does `last_plot()` do?  

> your answer...

What are we adding in the followin plot?

> your answer...
  
```{r}  
last_plot() +
  geom_vline(xintercept = sample_proportion, # what's actually observed
             color = "red") +
  geom_vline(xintercept = .5 - (sample_proportion - .5), # symmetrical distance from pi
             color = "red", linetype = "dashed")
```


### Step 3: Describe how consistent/inconsistent using z-statistic (number of standard deviations from the mean of the null model)

```{r}
## calculate z score
(sample_proportion - null_prob) /
  sd_chance_model ->
z_score

z_score
```

### Step 4: translate z-score to p-value

Using `pnorm()` we translate from the z-score to a p-value, the probability of observing something as extreme or more extreme than the observed outcome, just by chance...  Here we use the 2 tailed test.  The case where we don't have a strong expectation about the direction of the effect - blue *or* red might be advantageous.

```{r}
# situate in normal distribution 
(1 - pnorm(abs(z_score))) * 2 # we are multiplying times two if two-sided
```

If my critical value $\alpha$ is .05, is the p-value small enough to reject the null hypothesis, $H_0\neq .5$?

> your answer here...

If I have a strong prior expectation -- being clad in *red* -- a threat color in nature -- I should expect to win more, I might conduct a *one sided test.*  In this case, what is the p-value? 

When 

$$H_0 \leq 5,  H_A>.5 $$ 
$$p-value = ? $$

---

## Part 1.b. Using `prop.test()` function will do this for you too.

```{r echo = T, comment="", warning=F}
prop.test(x = 248, # number "successes" observed 
          n = 457, # total number observed
          p = .5, # proportion expected under null, pi
          alternative = "two.sided", # which extremes count for alternative hypothesis, other options is "greater" "less" for one sided
          correct = F) # use classic prop test
```



There is quite a lot of output, but you should be familiar with many elements.  What are some of the statistics that look familiar. **Replace question marks below with numerical values or text**

Based on the output:

- $p-value$ = ?
- null probability, $\pi$ = ?
- sample estimate, i.e. the observed proportion, $\hat{p}$ = ?
- alternative hypothesis, $H_A$ = ?

We will also talk about confidence intervals soon.  What is the reported confidence interval?

> your answer here

Confirm that the p-value you calculated in the 4-step process is the same as `prop.test()`

> Is it the same? Y/N





## prop.test() exercise for generalizing to a population

Change the values for the NYC Mayor Bloomberg Big Gulp Ban question.

1093 individuals of NYC 4 million registered voters were polled using a ...

> choose 1 (simple random sample/ convenience sample)

503 respondents supported the ban (46% or 1093) on super-sized sweet drinks.

Is there evidence that overall the population of voters preference is different than 50-50 support?  I.e. is there statistically significant evidence against the null, $H_0=.5$?

Below the inputs are set up for the olympics example.  Change them, and answer the question.

```{r echo = T, comment="", warning=F}
# set up for boxing, change to big gulp!
prop.test(x = 248, # number "successes" observed 
          n = 457, # total number observed
          p = .5, # proportion expected under null, pi
          alternative = "greater", # which extremes count, other options is "greater" "less" for one sided
          correct = F) # use classic prop test
```


Based on the output once you've changed the test to the big gulp, super-sized drinks case fill in the values:

- $p-value$ = ?
- null probability, $\pi$ = ?
- sample estimate, i.e. the observed proportion, $\hat{p}$ = ?
- alternative hypothesis, $H_A$ = ?

# Part II. Continuous variable and the t-statistic

*Now, create a plot using the song lengths data.*

Here is the scenario:  48 people are asked to say how long they think a song snippet was (10 seconds of a Jackson 5 song they just heard).  The researchers want to know: on average do people tend to overestimate the song length or underestimate, or can't we say (consistent with neither over or underestimation - the null of 10 seconds on average).

```{r}
# read in data (posted online) of time estimates for time-laps when a 10 second clip is played
read_csv(file = "https://raw.githubusercontent.com/EvaMaeRey/teaching_spring_2021/master/data/chap2.ElapsedTime.csv") %>% 
  rename(time = Time) -> # rename Time as time - this is snake case a coding style that I prefer
  jackson_five

# you've read in the data and created the object:
jackson_five
```

**How many observations are there?**

> your answer here...

```{r}
ggplot(data = jackson_five) + 
  aes(x = time) + # time estimate responses from people
  geom_rug(alpha = .1) + # alpha adjusts transparency of hashes
  geom_histogram() +
  geom_vline(xintercept = 10, # known song snippet length
             linetype = "dashed") +
  geom_vline(xintercept = 30) +
  theme_minimal() +
  labs(title = "Do we have evidence that on average people tend to overestimate \nor underestimatethe Jackson 5 song snippet length?\nOr is what's observed consistent with the null -\ni.e. not overestimating or underestimating on average\n(10 seconds is actually played)")
```

If the mean and median of the data are somewhat different, it is evidence of skew.

```{r}
mean(jackson_five$time)
median(jackson_five$time)
```

**Answer**, Is there some evidence of skew?

>  your answer:  yes/no

If skewed, in what direction?

> **keep the correct response:**  right (mean is > median - outlying, "unusual" values are pulling to the right) or left (mean is < median - outlying, "unusual" values are pulling to the left)



**Task: In the plot above, change "30" in geom_vline(xintercept = 30) to the value of the mean.**

## Part II.a: calculating the t-statistic and p-value by hand

$$t-statistic = \frac{\bar{x} - \mu}{SE}$$
Where SE is the standard *error*.  The sampling error is our expectation about how far away our mean might be from our true mean for any given sample from a population.  The central limit theorem tells us that for repeated samples, the mean will center on the population mean, and the distribution will be a fraction of the population standard deviation - specifically: the standard deviation divided by the square root of the sample size!  

$$SE = \frac{\sigma}{\sqrt{n}}$$
Sigma is unknown (this is the standard deviation for the population, but we just have a sample), so we use $s$. $s$ denotes the sample standard deviation, in place of $\sigma$, the population standard deviation.

All together:

$$t-statistic = \frac{\bar{x} - \mu}{s/\sqrt{n}}$$

First we calculate the standard error.

```{r}
sd(jackson_five$time)/sqrt(nrow(jackson_five)) ->
  standard_error
```

Then, we need to figure out how far away, in standard errors, our observe mean $\bar{x}$ is from the $\mu$, the parameter (10 seconds).  the t-statistic, like the z-score, is a standardized statistic

```{r}
mean(jackson_five$time) - 10 ->
  observed_v_parameter_difference

observed_v_parameter_difference/standard_error ->
  t_stat

t_stat
```

Complete the following sentence by rounding the t-stat to the nearest whole number:

> The observed mean is about ?? standard errors away from the parameter, 10.  


## Part II.b Using `t.test()`

```{r}
t.test(x = jackson_five$time, 
       mu = 10)
```

Verify that our t-stat matches the t.test result.

> Does it match? Y/N


Is this standardized statistic, the t-statistic, large enough to justify rejecting the null if my alpha level is .05 (you can look at the p-value too).  

> Yes/No

If my alpha level is .01

> Yes/No


Note:  If we reject the null based on a critical value alpha, then we may say that the result is *statistically significant*.


# Confidence intervals

Provide the definition of a confidence interval that the book gives here.  

> The book definition is ...
